import streamlit as st
import pandas as pd
import numpy as np
import os
import plotly.graph_objects as go
import plotly.express as px
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans
from chroma_utils import load_chroma_collection, get_available_collections, hybrid_query_chroma
# WordCloud ì¶”ê°€
from wordcloud import WordCloud
from konlpy.tag import Okt
import matplotlib.pyplot as plt
from text_utils import KOREAN_STOPWORDS # text_utilsì—ì„œ ë¶ˆìš©ì–´ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
import matplotlib.font_manager as fm
import random # ë¬´ì‘ìœ„ ì„ íƒì„ ìœ„í•´ ì¶”ê°€

st.set_page_config(
    page_title="DB ê²€ìƒ‰",
    page_icon="ğŸ”",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'chroma_client' not in st.session_state:
    st.session_state.chroma_client = None
if 'chroma_collection' not in st.session_state:
    st.session_state.chroma_collection = None
if 'collection_loaded' not in st.session_state:
    st.session_state.collection_loaded = False
if 'current_collection_name' not in st.session_state:
    st.session_state.current_collection_name = None
if 'current_db_path' not in st.session_state:
    st.session_state.current_db_path = None

st.title("DB ê²€ìƒ‰")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("DB ì„¤ì •")
    
    # ChromaDB ê²½ë¡œ ì„¤ì •
    default_db_path = "./chroma_db"
    db_path = st.text_input(
        "ChromaDB ê²½ë¡œ",
        value=default_db_path,
        help="ChromaDBê°€ ì €ì¥ëœ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”. ê¸°ë³¸ê°’ì€ './chroma_db'ì…ë‹ˆë‹¤."
    )
    
    # ê²½ë¡œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not os.path.exists(db_path):
        st.warning(f"ì…ë ¥í•œ ê²½ë¡œ({db_path})ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê¸°ë³¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        db_path = default_db_path
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    collections = get_available_collections(persist_directory=db_path)
    
    if not collections:
        st.error(f"'{db_path}' ê²½ë¡œì— ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
        selected_collection = None
        # ì»¬ë ‰ì…˜ì´ ì—†ìœ¼ë©´ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        st.session_state.collection_loaded = False
        st.session_state.chroma_client = None
        st.session_state.chroma_collection = None
    else:
        selected_collection = st.selectbox(
            "ì»¬ë ‰ì…˜ ì„ íƒ",
            options=collections,
            index=0 if collections else None,
            help="ê²€ìƒ‰í•  ChromaDB ì»¬ë ‰ì…˜ì„ ì„ íƒí•˜ì„¸ìš”."
        )
        
        # ì»¬ë ‰ì…˜ì´ë‚˜ ê²½ë¡œê°€ ë³€ê²½ë˜ë©´ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
        if (selected_collection != st.session_state.current_collection_name or 
            db_path != st.session_state.current_db_path):
            st.session_state.collection_loaded = False
            st.session_state.current_collection_name = selected_collection
            st.session_state.current_db_path = db_path
            
    # ì»¬ë ‰ì…˜ ë¡œë“œ ë²„íŠ¼
    if selected_collection and not st.session_state.collection_loaded:        
        if st.button("ì»¬ë ‰ì…˜ ë¡œë“œ", key="load_collection_btn"):
            with st.spinner("ì»¬ë ‰ì…˜ì„ ë¡œë“œí•˜ëŠ” ì¤‘..."):
                try:
                    client, collection = load_chroma_collection(
                        collection_name=selected_collection,
                        persist_directory=db_path
                    )
                    st.session_state.chroma_client = client
                    st.session_state.chroma_collection = collection
                    st.session_state.collection_loaded = True
                    st.success(f"ì»¬ë ‰ì…˜ '{selected_collection}'ì„ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    st.error(f"ì»¬ë ‰ì…˜ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            
    
    # ì»¬ë ‰ì…˜ì´ ë¡œë“œëœ ê²½ìš° ìƒíƒœ í‘œì‹œ
    if st.session_state.collection_loaded:
        # ì»¬ë ‰ì…˜ ì •ë³´ í‘œì‹œ
        with st.expander("ì»¬ë ‰ì…˜ ì •ë³´"):
            try:
                # ì´ë¯¸ ë¡œë“œëœ ì»¬ë ‰ì…˜ ì‚¬ìš©
                collection = st.session_state.chroma_collection
                collection_info = collection.count()
                
                # ì»¬ë ‰ì…˜ì— ì €ì¥ëœ ì„ë² ë”© ëª¨ë¸ ì •ë³´ í™•ì¸
                embedding_model = "ì•Œ ìˆ˜ ì—†ìŒ"
                try:
                    if collection.metadata and "embedding_model" in collection.metadata:
                        embedding_model = collection.metadata["embedding_model"]
                except:
                    pass
                
                st.write(f"ì»¬ë ‰ì…˜ ì´ë¦„: {selected_collection}")
                st.write(f"ë¬¸ì„œ ìˆ˜: {collection_info}")
                st.write(f"ì„ë² ë”© ëª¨ë¸: {embedding_model}")
                st.write(f"DB ê²½ë¡œ: {db_path}")
            except Exception as e:
                st.error(f"ì»¬ë ‰ì…˜ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# íƒ­ ìƒì„±
tab1, tab2, tab3 = st.tabs(["ì»¬ë ‰ì…˜ ë°ì´í„°", "í…ìŠ¤íŠ¸ ê²€ìƒ‰", "ì‹œê°í™”"])

# ë©”ì¸ ì˜ì—­
if not collections:
    for tab in [tab1, tab2, tab3]:
        with tab:
            st.error(f"ì„ íƒí•œ ê²½ë¡œ({db_path})ì— ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  DBì— ì €ì¥í•´ì£¼ì„¸ìš”.")
else:
    # ì»¬ë ‰ì…˜ì´ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ì•ˆë‚´ ë©”ì‹œì§€
    if not st.session_state.collection_loaded:
        for tab in [tab1, tab2, tab3]:
            with tab:
                st.info("ì‚¬ì´ë“œë°”ì—ì„œ ì»¬ë ‰ì…˜ì„ ë¡œë“œí•˜ì„¸ìš”.")
    else:
        # íƒ­ 1: ì»¬ë ‰ì…˜ ë°ì´í„° í‘œì‹œ
        with tab1:
            st.subheader(f"ì»¬ë ‰ì…˜: {selected_collection}")
            
            # ë°ì´í„° ë¡œë“œ ë²„íŠ¼
            if st.button("ë°ì´í„° í‘œì‹œ", key="show_data_btn"):
                with st.spinner("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                    try:
                        # ì´ë¯¸ ë¡œë“œëœ ì»¬ë ‰ì…˜ ì‚¬ìš©
                        collection = st.session_state.chroma_collection
                        
                        # ì»¬ë ‰ì…˜ì˜ ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                        all_data = collection.get()
                        
                        if all_data and all_data["documents"]:
                            # ê²°ê³¼ í‘œì‹œ
                            st.success(f"ì´ {len(all_data['documents'])}ê°œì˜ ë¬¸ì„œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                            
                            # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
                            result_data = []
                            for i, (doc, metadata, id) in enumerate(zip(
                                all_data["documents"], 
                                all_data["metadatas"],
                                all_data["ids"]
                            )):
                                result_data.append({
                                    "ID": id,
                                    "ì¶œì²˜": metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ"),
                                    "ì²­í¬": metadata.get("chunk", "ì•Œ ìˆ˜ ì—†ìŒ"),
                                    "í‚¤ì›Œë“œ": metadata.get("keywords", "ì•Œ ìˆ˜ ì—†ìŒ"),
                                    "ë‚´ìš©": doc,
                                })
                            
                            # ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° í‘œì‹œ
                            result_df = pd.DataFrame(result_data)
                            st.dataframe(
                                result_df,
                                use_container_width=True,
                                hide_index=True,
                                column_config={
                                    "ID": st.column_config.TextColumn(width="medium"),
                                    "ì¶œì²˜": st.column_config.TextColumn(width="small"),
                                    "ì²­í¬": st.column_config.NumberColumn(width="small"),
                                    "í‚¤ì›Œë“œ": st.column_config.TextColumn(width="medium", help="ë¬¸ì„œì—ì„œ ì¶”ì¶œëœ ì£¼ìš” í‚¤ì›Œë“œì…ë‹ˆë‹¤."),
                                    "ë‚´ìš©": st.column_config.TextColumn(width="large"),
                                }
                            )
                            
                            # ë°ì´í„° í†µê³„
                            st.subheader("ë°ì´í„° í†µê³„")
                            st.write(f"ì´ ë¬¸ì„œ ìˆ˜: {len(all_data['documents'])}")
                            
                            # ì¶œì²˜ë³„ ë¬¸ì„œ ìˆ˜ ê³„ì‚°
                            source_counts = {}
                            for metadata in all_data["metadatas"]:
                                source = metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ")
                                source_counts[source] = source_counts.get(source, 0) + 1
                            
                            # ì¶œì²˜ë³„ ë¬¸ì„œ ìˆ˜ ì°¨íŠ¸
                            source_df = pd.DataFrame({
                                "ì¶œì²˜": list(source_counts.keys()),
                                "ë¬¸ì„œ ìˆ˜": list(source_counts.values())
                            })
                            st.bar_chart(source_df.set_index("ì¶œì²˜"))
                        else:
                            st.info("ì»¬ë ‰ì…˜ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
                    except Exception as e:
                        st.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        # íƒ­ 2: DB ê²€ìƒ‰
        with tab2:
            # ê²€ìƒ‰ ì„¤ì •
            with st.expander("ê²€ìƒ‰ ì„¤ì •", expanded=True):
                # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì„¤ì •
                n_results = st.slider(
                    "ê²€ìƒ‰ ê²°ê³¼ ìˆ˜",
                    min_value=1,
                    max_value=50,
                    value=10,
                    step=1,
                    help="ë°˜í™˜í•  ê²€ìƒ‰ ê²°ê³¼ì˜ ìµœëŒ€ ê°œìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
                )
            
            # ê²€ìƒ‰ ì…ë ¥ í•„ë“œ
            query = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", key="search_query")
            
            # ê²€ìƒ‰ ë²„íŠ¼
            search_button = st.button("ê²€ìƒ‰", type="primary")
            
            # ê²€ìƒ‰ ì‹¤í–‰
            if search_button and query:
                with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                    try:
                        # ì´ë¯¸ ë¡œë“œëœ ì»¬ë ‰ì…˜ ì‚¬ìš©
                        collection = st.session_state.chroma_collection
                        
                        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
                        results = hybrid_query_chroma(collection, query, n_results=n_results)
                        
                        if results and results["documents"] and results["documents"][0]:
                            # ê²°ê³¼ í‘œì‹œ
                            st.subheader(f"ê²€ìƒ‰ ê²°ê³¼: {len(results['documents'][0])}ê°œ")
                            
                            # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
                            result_data = []
                            for i, (doc, metadata, distance) in enumerate(zip(
                                results["documents"][0], 
                                results["metadatas"][0], 
                                results["distances"][0]
                            )):
                                # ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚° (ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜)
                                similarity = 1 - distance
                                
                                # ê²€ìƒ‰ ìœ í˜• í™•ì¸
                                search_type = "ì„ë² ë”©"
                                if "search_type" in results:
                                    search_type = "í‚¤ì›Œë“œ" if results["search_type"][0][i] == "keyword" else "ì„ë² ë”©"
                                
                                # ëª¨ë“  ê²°ê³¼ í‘œì‹œ
                                result_data.append({
                                    "ìˆœìœ„": i + 1,
                                    "ìœ ì‚¬ë„": f"{similarity:.4f}",
                                    "ê²€ìƒ‰ ìœ í˜•": search_type,
                                    "ì¶œì²˜": metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ"),
                                    "ì²­í¬": metadata.get("chunk", "ì•Œ ìˆ˜ ì—†ìŒ"),
                                    "í‚¤ì›Œë“œ": metadata.get("keywords", "ì•Œ ìˆ˜ ì—†ìŒ"),
                                    "ë‚´ìš©": doc,
                                })
                            
                            # ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° í‘œì‹œ
                            result_df = pd.DataFrame(result_data)
                            st.dataframe(
                                result_df,
                                use_container_width=True,
                                hide_index=True,
                                column_config={
                                    "ìˆœìœ„": st.column_config.NumberColumn(width="small"),
                                    "ìœ ì‚¬ë„": st.column_config.TextColumn(width="small"),
                                    "ê²€ìƒ‰ ìœ í˜•": st.column_config.TextColumn(width="small"),
                                    "ì¶œì²˜": st.column_config.TextColumn(width="small"),
                                    "ì²­í¬": st.column_config.NumberColumn(width="small"),
                                    "í‚¤ì›Œë“œ": st.column_config.TextColumn(width="medium", help="ë¬¸ì„œì—ì„œ ì¶”ì¶œëœ ì£¼ìš” í‚¤ì›Œë“œì…ë‹ˆë‹¤."),
                                    "ë‚´ìš©": st.column_config.TextColumn(width="large"),
                                }
                            )
                            
                            # ì‹œê°í™”: ìœ ì‚¬ë„ ì°¨íŠ¸
                            if len(result_data) > 1:
                                st.subheader("ìœ ì‚¬ë„ ë¶„í¬")
                                chart_data = pd.DataFrame({
                                    "ìˆœìœ„": [item["ìˆœìœ„"] for item in result_data],
                                    "ìœ ì‚¬ë„": [float(item["ìœ ì‚¬ë„"]) for item in result_data]
                                })
                                st.bar_chart(chart_data.set_index("ìˆœìœ„"))
                        else:
                            st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
                    except Exception as e:
                        st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        # íƒ­ 3: ì‹œê°í™”
        with tab3:
            st.subheader(f"ì»¬ë ‰ì…˜ ì‹œê°í™”: {selected_collection}")
            
            # ì‹œê°í™” ì„¤ì •
            with st.expander("ì‹œê°í™” ì„¤ì •", expanded=True):
                # í´ëŸ¬ìŠ¤í„° ìˆ˜ ì„¤ì •
                n_clusters = st.slider(
                    "í´ëŸ¬ìŠ¤í„° ìˆ˜",
                    min_value=2,
                    max_value=20,
                    value=5,
                    step=1,
                    help="ë¬¸ì„œë¥¼ ê·¸ë£¹í™”í•  í´ëŸ¬ìŠ¤í„°ì˜ ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
                )
                
                # ìµœëŒ€ ë¬¸ì„œ ìˆ˜ ì„¤ì •
                max_docs = st.slider(
                    "ìµœëŒ€ ë¬¸ì„œ ìˆ˜",
                    min_value=50,
                    max_value=1000,
                    value=200,
                    step=50,
                    help="ì‹œê°í™”í•  ìµœëŒ€ ë¬¸ì„œ ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ë¬¸ì„œê°€ ë§ì„ìˆ˜ë¡ ì²˜ë¦¬ ì‹œê°„ì´ ê¸¸ì–´ì§‘ë‹ˆë‹¤."
                )
                
                # ì°¨ì› ì¶•ì†Œ ë°©ë²• ì„ íƒ
                perplexity = st.slider(
                    "t-SNE ë³µì¡ë„(Perplexity)",
                    min_value=5,
                    max_value=50,
                    value=30,
                    step=5,
                    help="t-SNEê°€ ê° ë°ì´í„° í¬ì¸íŠ¸ ì£¼ë³€ì˜ 'ìœ íš¨ ì´ì›ƒ ìˆ˜'ë¥¼ ê²°ì •í•˜ëŠ” ê°’ì…ë‹ˆë‹¤. ë°ì´í„°ì˜ ì§€ì—­ì  êµ¬ì¡°ì™€ ì „ì—­ì  êµ¬ì¡° ì‚¬ì´ì˜ ê· í˜•ì— ì˜í–¥ì„ ì¤ë‹ˆë‹¤.\n\n"
                         "- **ë‚®ì€ ê°’ (5-15):** ë§¤ìš° ê°€ê¹Œìš´ ì´ì›ƒì— ì§‘ì¤‘í•˜ì—¬ ì„¸ë°€í•œ ì§€ì—­ì  êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤. ë„ˆë¬´ ë‚®ìœ¼ë©´ ë…¸ì´ì¦ˆì— ë¯¼ê°í•˜ê±°ë‚˜ ë¶ˆí•„ìš”í•˜ê²Œ ë§ì€ ì‘ì€ êµ°ì§‘ì´ ìƒê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
                         "- **ì¤‘ê°„ ê°’ (20-30):** ëŒ€ë¶€ë¶„ì˜ ë°ì´í„°ì…‹ì—ì„œ ì¢‹ì€ ì‹œì‘ì ì…ë‹ˆë‹¤. ì§€ì—­ì  êµ¬ì¡°ì™€ ì „ì—­ì  êµ¬ì¡° ê°„ì˜ ì ì ˆí•œ ê· í˜•ì„ ì œê³µí•©ë‹ˆë‹¤. (ê¸°ë³¸ê°’: 30)\n"
                         "- **ë†’ì€ ê°’ (35-50):** ë” ë„“ì€ ë²”ìœ„ì˜ ì´ì›ƒì„ ê³ ë ¤í•˜ì—¬ ë°ì´í„°ì˜ ì „ì—­ì ì¸ êµ¬ì¡°ë‚˜ í° êµ°ì§‘ì„ íŒŒì•…í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ë„ˆë¬´ ë†’ìœ¼ë©´ ì„¸ë°€í•œ êµ¬ì¡°ê°€ ë­‰ê°œì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"
                         "ë°ì´í„°ì…‹ì˜ í¬ê¸°ì™€ íŠ¹ì„±ì— ë”°ë¼ ì—¬ëŸ¬ ê°’ì„ ì‹œë„í•˜ë©° ê°€ì¥ ì˜ë¯¸ ìˆëŠ” íŒ¨í„´ì„ ë³´ì—¬ì£¼ëŠ” ê°’ì„ ì„ íƒí•˜ì„¸ìš”."
                )
            
            # ì„ë² ë”© ë°ì´í„° ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜
            def get_embeddings_data(collection, all_data, max_docs):
                """ì»¬ë ‰ì…˜ì—ì„œ ì„ë² ë”© ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
                total_docs = len(all_data["documents"])
                
                # ìµœëŒ€ ë¬¸ì„œ ìˆ˜ ì œí•œ ì ìš©
                if total_docs > max_docs:
                    st.info(f"ë¬¸ì„œê°€ ë„ˆë¬´ ë§ì•„ ë¬´ì‘ìœ„ë¡œ {max_docs}ê°œë¥¼ ì„ íƒí•˜ì—¬ ì‹œê°í™”í•©ë‹ˆë‹¤.")
                    # ë¬´ì‘ìœ„ ì¸ë±ìŠ¤ ì„ íƒ
                    random_indices = random.sample(range(total_docs), max_docs)
                    
                    # ì„ íƒëœ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì¶”ì¶œ
                    documents = [all_data["documents"][i] for i in random_indices]
                    metadatas = [all_data["metadatas"][i] for i in random_indices]
                    ids = [all_data["ids"][i] for i in random_indices]

                    # documents = all_data["documents"][:max_docs] # ì´ì „ ë°©ì‹
                    # metadatas = all_data["metadatas"][:max_docs] # ì´ì „ ë°©ì‹
                    # ids = all_data["ids"][:max_docs] # ì´ì „ ë°©ì‹


                    # ì œí•œëœ IDë¡œ ì„ë² ë”© ê°€ì ¸ì˜¤ê¸°
                    try:
                        embeddings_result = collection.get(
                            ids=ids,
                            include=["embeddings"]
                        )
                        embeddings = embeddings_result.get("embeddings", [])
                    except Exception as e:
                        st.warning(f"ì„ë² ë”© ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
                        embeddings = []
                else:
                    documents = all_data["documents"]
                    metadatas = all_data["metadatas"]
                    ids = all_data["ids"]
                    
                    # ëª¨ë“  ì„ë² ë”© ê°€ì ¸ì˜¤ê¸°
                    try:
                        embeddings_result = collection.get(
                            include=["embeddings"]
                        )
                        embeddings = embeddings_result.get("embeddings", [])
                    except Exception as e:
                        st.warning(f"ì„ë² ë”© ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
                        embeddings = []
                
                return documents, metadatas, ids, embeddings
            
            # ì„ë² ë”© ì—†ì„ ë•Œ ì²˜ë¦¬ í•¨ìˆ˜
            def handle_missing_embeddings(collection, documents):
                """ì„ë² ë”© ë°ì´í„°ê°€ ì—†ì„ ë•Œ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
                # ì»¬ë ‰ì…˜ ë©”íƒ€ë°ì´í„°ì—ì„œ ì„ë² ë”© ëª¨ë¸ ì •ë³´ í™•ì¸
                embedding_model = "ì•Œ ìˆ˜ ì—†ìŒ"
                try:
                    if collection.metadata and "embedding_model" in collection.metadata:
                        embedding_model = collection.metadata["embedding_model"]
                except:
                    pass
                
                # ì„ë² ë”© í•¨ìˆ˜ í™•ì¸
                has_embedding_function = hasattr(collection, "_embedding_function") and collection._embedding_function is not None
                
                if has_embedding_function:
                    st.warning(f"ì´ ì»¬ë ‰ì…˜ì€ '{embedding_model}' ì„ë² ë”© ëª¨ë¸ë¡œ ìƒì„±ë˜ì—ˆì§€ë§Œ, ì„ë² ë”© ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.info("ì»¬ë ‰ì…˜ì„ ë‹¤ì‹œ ë¡œë“œí•˜ê±°ë‚˜, ë°ì´í„°ë¥¼ ë‹¤ì‹œ ì €ì¥í•´ë³´ì„¸ìš”.")
                else:
                    st.warning("ì»¬ë ‰ì…˜ì— ì„ë² ë”© í•¨ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    st.info(f"ì´ ì»¬ë ‰ì…˜ì€ '{embedding_model}' ì„ë² ë”© ëª¨ë¸ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ë™ì¼í•œ ëª¨ë¸ë¡œ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ì €ì¥í•´ë³´ì„¸ìš”.")
                
                # ëŒ€ì²´ ì‹œê°í™” ë°©ë²• ì œì•ˆ
                st.info("ì„ë² ë”© ë°ì´í„° ì—†ì´ ì‹œê°í™”ë¥¼ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? ì„ì˜ì˜ ì„ë² ë”©ì„ ìƒì„±í•˜ì—¬ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                if st.button("ì„ì˜ ì„ë² ë”©ìœ¼ë¡œ ì‹œê°í™” ì§„í–‰", key="random_viz_btn"):
                    # ì„ì˜ì˜ ì„ë² ë”© ìƒì„± (ë¬¸ì„œ ìˆ˜ x 384 ì°¨ì›)
                    st.text("ì„ì˜ ì„ë² ë”© ìƒì„± ì¤‘...")
                    import numpy as np
                    random_dim = 384  # ì¼ë°˜ì ì¸ ì„ë² ë”© ì°¨ì›
                    num_docs = len(documents)
                    embeddings = np.random.rand(num_docs, random_dim)
                    st.success(f"ì„ì˜ì˜ {num_docs}x{random_dim} ì„ë² ë”©ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
                    return embeddings
                else:
                    st.stop()
                    return []
            
            # ì‹œê°í™” ë°ì´í„° ì¤€ë¹„ í•¨ìˆ˜
            def prepare_visualization_data(embeddings_array, documents, ids, metadatas, perplexity, n_clusters):
                """ì‹œê°í™”ë¥¼ ìœ„í•œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ëŠ” í•¨ìˆ˜"""
                # t-SNEë¡œ ì°¨ì› ì¶•ì†Œ
                st.text("t-SNEë¡œ ì°¨ì› ì¶•ì†Œ ì¤‘...")
                tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42)
                embeddings_2d = tsne.fit_transform(embeddings_array)
                
                # K-means í´ëŸ¬ìŠ¤í„°ë§
                st.text("í´ëŸ¬ìŠ¤í„°ë§ ì¤‘...")
                kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')
                clusters = kmeans.fit_predict(embeddings_array)
                
                # ë°ì´í„°í”„ë ˆì„ ìƒì„±
                viz_data = pd.DataFrame({
                    'x': embeddings_2d[:, 0],
                    'y': embeddings_2d[:, 1],
                    'cluster': clusters,
                    'id': ids,
                    'text': documents,  # ì „ì²´ í…ìŠ¤íŠ¸ í‘œì‹œ (hoverìš©)
                    'full_text': documents  # ì›ë³¸ í…ìŠ¤íŠ¸ (WordCloud ë° ìƒì„¸ ë‚´ìš© í‘œì‹œìš©)
                })
                
                # ì¶œì²˜ ì •ë³´ ì¶”ê°€
                viz_data['source'] = [metadata.get("source", "ì•Œ ìˆ˜ ì—†ìŒ") for metadata in metadatas]
                
                return viz_data
            
            # WordCloud ìƒì„± í•¨ìˆ˜
            # @st.cache_data(show_spinner=False) # ê²°ê³¼ ìºì‹±í•˜ì—¬ ë°˜ë³µ ìƒì„± ë°©ì§€
            def generate_wordcloud_for_cluster(_texts, _stopwords, _collection_name_for_cache, _cluster_id_for_cache): # ìºì‹œ í‚¤ì— í´ëŸ¬ìŠ¤í„° ID ì¶”ê°€
                from text_utils import clean_text # ì—¬ê¸°ì„œ import í•´ì•¼ ìºì‹±ì— ë¬¸ì œ ì—†ìŒ
                okt = Okt()
                nouns = []
                for text_content in _texts:
                    cleaned_text_for_nouns = clean_text(str(text_content)) # str()ë¡œ ëª…ì‹œì  ë³€í™˜
                    for noun in okt.nouns(cleaned_text_for_nouns):
                        if noun not in _stopwords and len(noun) > 1: # í•œ ê¸€ì ëª…ì‚¬ ì œì™¸
                            nouns.append(noun)
            
                if not nouns:
                    return None
            
                # í°íŠ¸ ê²½ë¡œ ì„¤ì •
                font_path = None
                preferred_fonts = ['NanumGothic', 'Malgun Gothic', 'AppleGothic', 'Noto Sans KR']
                font_list = fm.findSystemFonts(fontpaths=None, fontext='ttf')
                
                for font_file in font_list:
                    try:
                        font_name = fm.FontProperties(fname=font_file).get_name()
                        if any(preferred in font_name for preferred in preferred_fonts):
                            font_path = font_file
                            break
                    except RuntimeError:
                        continue # ì¼ë¶€ í°íŠ¸ íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥ì„±
            
                if not font_path:
                    # ìºì‹œ í•¨ìˆ˜ ë‚´ì—ì„œ st UI ìš”ì†Œ ì§ì ‘ í˜¸ì¶œ ì§€ì–‘
                    print("ì„ í˜¸í•˜ëŠ” í•œê¸€ í°íŠ¸(NanumGothic, Malgun Gothic ë“±)ë¥¼ ì‹œìŠ¤í…œì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
                # ìƒˆë¡œìš´ Figure ê°ì²´ ìƒì„±
                fig, ax = plt.subplots(figsize=(12, 6))
                try:
                    wordcloud = WordCloud(
                        font_path=font_path,
                        width=800,
                        height=400,
                        background_color='white',
                        collocations=False # ì—°ì–´(collocations) ë°©ì§€
                    ).generate(' '.join(nouns))
                    
                    ax.imshow(wordcloud, interpolation='bilinear')
                    ax.axis('off')
                    return fig # WordCloud ì´ë¯¸ì§€ ìì²´ê°€ ì•„ë‹Œ Figure ê°ì²´ë¥¼ ë°˜í™˜
                except Exception as e:
                    print(f"WordCloud ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}. í°íŠ¸ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    plt.close(fig) # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒì„±ëœ figure ë‹«ê¸°
                    return None

            # í´ëŸ¬ìŠ¤í„°ë³„ WordCloud í‘œì‹œ í•¨ìˆ˜
            def display_cluster_wordclouds(viz_data, n_clusters, stopwords, current_collection_name):
                st.subheader("í´ëŸ¬ìŠ¤í„°ë³„ ì£¼ìš” ë‹¨ì–´ (WordCloud)")

                # í°íŠ¸ ê²½ë¡œ ë¯¸ë¦¬ í™•ì¸ (ê²½ê³  ë©”ì‹œì§€ìš©)
                font_path_exists = False
                preferred_fonts = ['NanumGothic', 'Malgun Gothic', 'AppleGothic', 'Noto Sans KR']
                font_list = fm.findSystemFonts(fontpaths=None, fontext='ttf')
                for font_file in font_list:
                    try:
                        font_name = fm.FontProperties(fname=font_file).get_name()
                        if any(preferred in font_name for preferred in preferred_fonts):
                            font_path_exists = True
                            break
                    except RuntimeError:
                        continue
                if not font_path_exists:
                    st.sidebar.warning("ì„ í˜¸í•˜ëŠ” í•œê¸€ í°íŠ¸(NanumGothic, Malgun Gothic ë“±)ë¥¼ ì‹œìŠ¤í…œì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. WordCloudê°€ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í°íŠ¸ ì„¤ì¹˜ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")

                for cluster_id in range(n_clusters):
                    cluster_texts = viz_data[viz_data['cluster'] == cluster_id]['full_text'].tolist()
                    
                    with st.expander(f"í´ëŸ¬ìŠ¤í„° {cluster_id} WordCloud ({len(cluster_texts)}ê°œ ë¬¸ì„œ)"):
                        if not cluster_texts:
                            st.write(f"í´ëŸ¬ìŠ¤í„° {cluster_id}: ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            continue
                        # generate_wordcloud_for_cluster í•¨ìˆ˜ í˜¸ì¶œ ì‹œ í´ëŸ¬ìŠ¤í„° IDë„ ì „ë‹¬
                        wordcloud_fig = generate_wordcloud_for_cluster(cluster_texts, stopwords, current_collection_name, cluster_id)
                        if wordcloud_fig:
                            st.pyplot(wordcloud_fig)
                            plt.close(wordcloud_fig) # ì‚¬ìš© í›„ figure ë‹«ê¸°
                        else:
                            st.write("WordCloudë¥¼ ìƒì„±í•  ì¶©ë¶„í•œ ë‹¨ì–´ê°€ ì—†ê±°ë‚˜, ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

            # ì‹œê°í™” ë²„íŠ¼
            if st.button("ì‹œê°í™” ìƒì„±", key="create_viz_btn", type="primary"):
                with st.spinner("ì‹œê°í™”ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘... ì´ ì‘ì—…ì€ ë°ì´í„° í¬ê¸°ì— ë”°ë¼ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."):
                    try:
                        # ì´ë¯¸ ë¡œë“œëœ ì»¬ë ‰ì…˜ ì‚¬ìš©
                        collection = st.session_state.chroma_collection
                        
                        # ì»¬ë ‰ì…˜ì˜ ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                        all_data = collection.get()
                        
                        if all_data and all_data["documents"]:
                            # ê²°ê³¼ í‘œì‹œ
                            total_docs = len(all_data["documents"])
                            st.success(f"ì´ {total_docs}ê°œì˜ ë¬¸ì„œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                            
                            # ì„ë² ë”© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                            documents, metadatas, ids, embeddings = get_embeddings_data(collection, all_data, max_docs)
                            
                            # ì„ë² ë”©ì´ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
                            if len(embeddings) == 0:
                                st.error("ì„ë² ë”© ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                embeddings = handle_missing_embeddings(collection, documents)
                            
                            # ì„ë² ë”© ë°°ì—´ë¡œ ë³€í™˜
                            embeddings_array = np.array(embeddings)
                            
                            # ì‹œê°í™” ë°ì´í„° ì¤€ë¹„
                            viz_data = prepare_visualization_data(
                                embeddings_array, documents, ids, metadatas, perplexity, n_clusters
                            )
                            
                            # Plotlyë¡œ ì‹œê°í™”
                            st.subheader("ë¬¸ì„œ í´ëŸ¬ìŠ¤í„° ì‹œê°í™”")
                            
                            # í´ëŸ¬ìŠ¤í„°ë³„ ìƒ‰ìƒ ì„¤ì •
                            colors = px.colors.qualitative.Plotly
                            
                            # í´ëŸ¬ìŠ¤í„° ìˆ˜ì— ë§ê²Œ ìƒ‰ìƒ í™•ì¥
                            while len(colors) < n_clusters:
                                colors.extend(colors)
                            colors = colors[:n_clusters]
                            
                            # ê·¸ë˜í”„ ìƒì„±
                            fig = go.Figure()
                            
                            # í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ì  ì¶”ê°€
                            def add_cluster_traces(fig, viz_data, n_clusters, colors):
                                """í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ê·¸ë˜í”„ì— ì  ì¶”ê°€"""
                                for cluster_id in range(n_clusters):
                                    cluster_data = viz_data[viz_data['cluster'] == cluster_id]
                                    
                                    fig.add_trace(go.Scatter(
                                        x=cluster_data['x'],
                                        y=cluster_data['y'],
                                        mode='markers',
                                        marker=dict(
                                            size=10,
                                            color=colors[cluster_id],
                                            line=dict(width=1, color='DarkSlateGrey')
                                        ),
                                        name=f'í´ëŸ¬ìŠ¤í„° {cluster_id}',
                                        text=cluster_data['text'],
                                        hoverinfo='text',
                                        hovertemplate='<b>ì¶œì²˜:</b> %{customdata}<br><b>ë‚´ìš©:</b> %{text}<extra></extra>',
                                        customdata=cluster_data['source']
                                    ))
                                return fig
                            
                            # í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ì  ì¶”ê°€
                            fig = add_cluster_traces(fig, viz_data, n_clusters, colors)
                            
                            # ë ˆì´ì•„ì›ƒ ì„¤ì •
                            fig.update_layout(
                                title='ë¬¸ì„œ í´ëŸ¬ìŠ¤í„° ì‹œê°í™” (t-SNE + K-means)',
                                xaxis=dict(title='t-SNE ì°¨ì› 1', showgrid=True),
                                yaxis=dict(title='t-SNE ì°¨ì› 2', showgrid=True),
                                hovermode='closest',
                                legend_title='í´ëŸ¬ìŠ¤í„°',
                                width=800,
                                height=600
                            )
                            
                            # ê·¸ë˜í”„ í‘œì‹œ
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # í´ëŸ¬ìŠ¤í„° í†µê³„ ì‹œê°í™”
                            def visualize_cluster_statistics(viz_data, colors):
                                """í´ëŸ¬ìŠ¤í„° í†µê³„ë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜"""
                                st.subheader("í´ëŸ¬ìŠ¤í„° í†µê³„")
                                cluster_counts = viz_data['cluster'].value_counts().reset_index()
                                cluster_counts.columns = ['í´ëŸ¬ìŠ¤í„°', 'ë¬¸ì„œ ìˆ˜']
                                
                                # í´ëŸ¬ìŠ¤í„°ë³„ ë¬¸ì„œ ìˆ˜ ì°¨íŠ¸
                                fig_bar = go.Figure(go.Bar(
                                    x=cluster_counts['í´ëŸ¬ìŠ¤í„°'],
                                    y=cluster_counts['ë¬¸ì„œ ìˆ˜'],
                                    marker_color=colors[:len(cluster_counts)]
                                ))
                                fig_bar.update_layout(
                                    title='í´ëŸ¬ìŠ¤í„°ë³„ ë¬¸ì„œ ìˆ˜',
                                    xaxis=dict(title='í´ëŸ¬ìŠ¤í„°'),
                                    yaxis=dict(title='ë¬¸ì„œ ìˆ˜')
                                )
                                st.plotly_chart(fig_bar, use_container_width=True)
                            
                            # í´ëŸ¬ìŠ¤í„° í†µê³„ ì‹œê°í™”
                            visualize_cluster_statistics(viz_data, colors)
                            
                            # í´ëŸ¬ìŠ¤í„°ë³„ WordCloud í‘œì‹œ
                            display_cluster_wordclouds(viz_data, n_clusters, KOREAN_STOPWORDS, selected_collection)
                            
                            # í´ëŸ¬ìŠ¤í„°ë³„ ì£¼ìš” ë¬¸ì„œ í‘œì‹œ
                            def display_cluster_documents(viz_data, n_clusters):
                                """í´ëŸ¬ìŠ¤í„°ë³„ ì£¼ìš” ë¬¸ì„œë¥¼ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜"""
                                st.subheader("í´ëŸ¬ìŠ¤í„°ë³„ ì£¼ìš” ë¬¸ì„œ")
                                for cluster_id in range(n_clusters):
                                    cluster_docs = viz_data[viz_data['cluster'] == cluster_id]
                                    with st.expander(f"í´ëŸ¬ìŠ¤í„° {cluster_id} ì£¼ìš” ë¬¸ì„œ ({len(cluster_docs)}ê°œ ë¬¸ì„œ)"):
                                        for _, row in cluster_docs.head(5).iterrows():
                                            # ì›ë³¸ í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ í‘œì‹œ
                                            st.markdown(f"**ì¶œì²˜:** {row['source']}")
                                            st.markdown(f"**ë‚´ìš©:** {row['full_text']}")
                                            st.markdown("---")
                            
                            # í´ëŸ¬ìŠ¤í„°ë³„ ì£¼ìš” ë¬¸ì„œ í‘œì‹œ
                            display_cluster_documents(viz_data, n_clusters)
                        else:
                            st.info("ì»¬ë ‰ì…˜ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
                    except Exception as e:
                        st.error(f"ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                        st.exception(e)

# ë„ì›€ë§ ì„¹ì…˜
with st.expander("ì‚¬ìš© ë°©ë²•"):
    st.markdown("""
    ### DB ê²€ìƒ‰ ì‚¬ìš© ë°©ë²•
    
    #### ê³µí†µ ì„¤ì •
    1. ì‚¬ì´ë“œë°”ì—ì„œ ChromaDB ê²½ë¡œë¥¼ ì…ë ¥í•©ë‹ˆë‹¤. (ê¸°ë³¸ê°’: './chroma_db')
    2. ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ì„ ì„ íƒí•©ë‹ˆë‹¤.
    3. 'ì»¬ë ‰ì…˜ ë¡œë“œ' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì»¬ë ‰ì…˜ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œí•©ë‹ˆë‹¤.
    
    #### ì»¬ë ‰ì…˜ ë°ì´í„° íƒ­
    - 'ë°ì´í„° í‘œì‹œ' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì„ íƒí•œ ì»¬ë ‰ì…˜ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ë°ì´í„° í†µê³„ë¥¼ í†µí•´ ì¶œì²˜ë³„ ë¬¸ì„œ ìˆ˜ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    #### DB ê²€ìƒ‰ íƒ­
    1. ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.
    2. ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ê³  'ê²€ìƒ‰' ë²„íŠ¼ì„ í´ë¦­í•©ë‹ˆë‹¤.
    3. ê²€ìƒ‰ ê²°ê³¼ëŠ” ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ë©ë‹ˆë‹¤.
    
    #### ì‹œê°í™” íƒ­
    1. í´ëŸ¬ìŠ¤í„° ìˆ˜, ìµœëŒ€ ë¬¸ì„œ ìˆ˜, t-SNE ë³µì¡ë„ ë“±ì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    2. 'ì‹œê°í™” ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë¬¸ì„œ í´ëŸ¬ìŠ¤í„° ì‹œê°í™”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    3. í´ëŸ¬ìŠ¤í„°ë³„ ë¬¸ì„œ ë¶„í¬ì™€ ì£¼ìš” ë¬¸ì„œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    ### í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
    
    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì€ ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ ê²€ìƒ‰ê³¼ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ì„ ê²°í•©í•©ë‹ˆë‹¤.
    - ë‹¨ì–´ ê²€ìƒ‰ì— ë” íš¨ê³¼ì ì´ë©°, ì •í™•í•œ ë‹¨ì–´ ë§¤ì¹­ì„ í¬í•¨í•©ë‹ˆë‹¤.
    - ê²€ìƒ‰ ê²°ê³¼ì— 'ê²€ìƒ‰ ìœ í˜•'ì´ í‘œì‹œë©ë‹ˆë‹¤. (ì„ë² ë”© ë˜ëŠ” í‚¤ì›Œë“œ)
    
    ### ChromaDB ê²½ë¡œ
    
    ë‹¤ë¥¸ í´ë”ì— ì €ì¥ëœ ChromaDBë¥¼ ê²€ìƒ‰í•˜ë ¤ë©´ í•´ë‹¹ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.
    ìƒëŒ€ ê²½ë¡œ(ì˜ˆ: './chroma_db') ë˜ëŠ” ì ˆëŒ€ ê²½ë¡œ(ì˜ˆ: 'C:/Users/username/chroma_db')ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    ### ì„ë² ë”© ëª¨ë¸
    
    ê²€ìƒ‰ ì‹œ ì»¬ë ‰ì…˜ì— ì €ì¥ëœ ì„ë² ë”© ëª¨ë¸ì´ ìë™ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    ì»¬ë ‰ì…˜ ì •ë³´ì—ì„œ ì‚¬ìš© ì¤‘ì¸ ì„ë² ë”© ëª¨ë¸ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    ### ìœ ì‚¬ë„ ì ìˆ˜
    
    ìœ ì‚¬ë„ ì ìˆ˜ëŠ” 0ì—ì„œ 1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê²€ìƒ‰ì–´ì™€ ìœ ì‚¬í•œ ë‚´ìš©ì…ë‹ˆë‹¤.
    í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ì˜ ê²½ìš° ìœ ì‚¬ë„ ì ìˆ˜ëŠ” ì„ì˜ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.
    
    ### ì‹œê°í™” ì •ë³´
    
    ì‹œê°í™” íƒ­ì—ì„œëŠ” t-SNE ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê³ ì°¨ì› ì„ë² ë”©ì„ 2ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œí•˜ê³ , K-means í´ëŸ¬ìŠ¤í„°ë§ì„ í†µí•´ ìœ ì‚¬í•œ ë¬¸ì„œë“¤ì„ ê·¸ë£¹í™”í•©ë‹ˆë‹¤.
    - ê° ì ì€ í•˜ë‚˜ì˜ ë¬¸ì„œë¥¼ ë‚˜íƒ€ë‚´ë©°, ìƒ‰ìƒì€ í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ë¶„í•©ë‹ˆë‹¤.
    - ì  ìœ„ì— ë§ˆìš°ìŠ¤ë¥¼ ì˜¬ë¦¬ë©´ ë¬¸ì„œ ë‚´ìš©ê³¼ ì¶œì²˜ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - í´ëŸ¬ìŠ¤í„°ë³„ ë¬¸ì„œ ìˆ˜ì™€ ì£¼ìš” ë¬¸ì„œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)